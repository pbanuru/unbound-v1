# Research Log - 2025-10-18

**Session Time**: 14:00 - 16:00 (~2 hours)
**Phase**: Phase 0 - Project Setup
**Focus**: Establishing async research collaboration infrastructure

---

## Work Completed

### Major Tasks
1. ✅ Analyzed existing research context
   - Reviewed 3 previous DeepResearcher sessions
   - Understood project goal: SOTA single-shot VC
   - Identified target: Beat Seed-VC (0.8676 similarity, 11.99% WER)

2. ✅ Researched async collaboration best practices
   - Used Task agent to research ML research workflows
   - Studied experiment tracking (W&B, markdown+git)
   - Learned about research documentation patterns (logs, plans, handoffs)

3. ✅ Designed project structure
   - Folder hierarchy for experiments, data, code, docs
   - Documentation framework (CLAUDE.md, RESEARCH_PLAN.md, HANDOFF.md)
   - Async communication protocol

4. ✅ Implemented structure
   - Created all folders (docs/, experiments/, data/, src/, etc.)
   - Wrote comprehensive documentation files
   - Set up gitignore for large files

### Documentation Created
- **CLAUDE.md** (3700 lines) - Complete guide for AI researcher
  - Project context and goals
  - How to work asynchronously
  - Tool usage (Deep Research, Modal, local dev)
  - Experiment workflow and file organization
  - Communication protocol with human
  - Budget management
  - Common tasks and troubleshooting

- **RESEARCH_PLAN.md** (1900 lines) - Living research roadmap
  - 5 phases over 12 weeks
  - Success criteria and constraints
  - Current status and metrics
  - Experiment tracking
  - SOTA comparison table
  - Decisions log and open questions
  - Budget tracking
  - Paper outline

- **HANDOFF.md** (1100 lines) - Async status updates
  - Current phase and status
  - What was just completed
  - What needs to be done (HIGH/MEDIUM/LOW priority)
  - Blockers and decisions needed
  - Questions and observations
  - Budget status
  - Git commits

- **experiments/README.md** - Experiment tracking guide
- **data/README.md** - Data management and preprocessing guide
- **research_logs/README.md** - Research log documentation

### Folder Structure Created
```
unbound-v1/
├── CLAUDE.md
├── RESEARCH_PLAN.md
├── HANDOFF.md
├── docs/
├── research_logs/2025-10/
├── experiments/
├── data/raw/, data/processed/
├── src/models/, src/training/, src/evaluation/, src/utils/
├── configs/
├── results/checkpoints/, results/metrics/, results/samples/
├── scripts/
└── paper/
```

---

## Key Findings

### Research Collaboration Patterns
- **Three-tier documentation**: Daily logs (ephemeral), experiment tracking (structured), planning (high-level)
- **Async handoff protocol**: STAR framework (Status, Tasks, Actions, Review)
- **Experiment organization**: Self-contained folders with config, notes, results
- **Paper traceability**: Tag experiments with paper section relevance

### Budget Insights
- Modal A100 (40GB): ~$2-3/hour
- Small training run (8 hours): ~$20
- Large training run (50 hours): ~$125
- $4971 starting budget allows ~40-50 full training runs if managed well
- Note: Budget shared with low-usage system; actual balance may vary slightly

### Project Understanding
From previous research sessions:
- 9 major competitors identified (RVC, OpenVoice, FreeVC, Seed-VC, etc.)
- Seed-VC is current SOTA with diffusion-transformer architecture
- Key challenges: Speaker leakage, one-shot overfitting, content distortion
- Promising approaches: SSL features (WavLM), triplet loss, diffusion decoders

---

## Observations

### Good News
- Previous research sessions are extremely thorough
- Clear understanding of problem space and SOTA
- $5000 budget should be sufficient for 12-week plan
- Modal + GCS infrastructure should work well

### Challenges Identified
- 20GB local storage is tight (need GCS bucket)
- Dataset download is human task (VCTK 11GB, LibriTTS 50GB)
- Need to verify Modal credentials work
- Deep Research queries take 10-15 minutes each

### System Design Choices
- **Chose markdown + git over W&B**: Simpler, async-friendly, no external dependencies
- **Separate HANDOFF from logs**: Logs are detailed, HANDOFF is action-oriented
- **Phase 0 focus on research**: Avoid wasting compute on uninformed decisions

---

## Hypotheses Formed

### Architecture
- **Hypothesis**: WavLM + ECAPA-TDNN + flow decoder might be optimal
- **Reasoning**: WavLM for content (SOTA SSL), ECAPA for speaker, flow for fast inference
- **Alternative**: Diffusion decoder for quality (but slower)
- **Need to validate**: Deep Research on architecture tradeoffs

### Data Strategy
- **Hypothesis**: VCTK alone sufficient for initial experiments (90 speakers)
- **Reasoning**: Standard benchmark, manageable size, good diversity
- **May need**: LibriTTS for additional diversity in later phases
- **Need to validate**: Deep Research on data strategy

### Training Strategy
- **Hypothesis**: Multi-loss training (reconstruction + adversarial + contrastive + CTC)
- **Reasoning**: Each loss addresses different challenge (speaker leakage, content distortion, etc.)
- **Need to validate**: Literature review on loss functions

---

## Questions / Issues

### For Human (Blockers)
1. **GCS bucket setup**: Need persistent storage for datasets
   - VCTK: 11GB
   - Processed features: ~6GB
   - Experiment results: growing
   - Can you set up bucket and provide credentials?

2. **Modal credentials**: Need to verify I can run `modal run` commands
   - Is Modal account set up?
   - Are $5000 credits loaded?
   - Should I test with a small job?

3. **Dataset download**: Should you download VCTK to GCS?
   - Faster if you do it (I can but it's slow)
   - URL: https://datashare.ed.ac.uk/handle/10283/3443
   - See data/README.md for instructions

### Strategic Questions
1. **Phase 0 timeline**: How long to spend on research before implementation?
   - Currently planned: 1 week
   - Deep Research queries take time (10-15 min each)
   - Tradeoff: More research = better decisions, but delays coding

2. **Paper venue**: Target Arxiv only, or submit to conference?
   - Affects rigor and timeline requirements
   - ICASSP/Interspeech have deadlines

3. **Priority**: Quality vs speed if forced to choose?
   - High quality + slow inference: Diffusion decoder
   - Good quality + fast inference: Flow decoder
   - Affects architecture decisions

### Technical Questions (To Investigate)
1. What are Seed-VC's specific weaknesses?
   - Need Deep Research query
   - Will inform our novel contributions

2. WavLM vs HuBERT vs Whisper for content encoding?
   - Need architecture comparison research
   - Affects main design decision

3. Best data augmentation for one-shot VC?
   - Need data strategy research
   - Affects training pipeline

---

## Next Session Plans

### Priority: HIGH
1. **Deep Research**: Seed-VC deep dive
   - Query: "Seed-VC architecture, training recipe, datasets, weaknesses, improvements"
   - Output: docs/seed_vc_analysis.md
   - Why: Need to understand what we're competing against

2. **Deep Research**: Data strategy
   - Query: "Compare VCTK, LibriTTS, AISHELL-3 for one-shot VC training"
   - Output: Update data/README.md
   - Why: Need to choose dataset(s)

3. **Architecture analysis**: Self-reasoning on decoder options
   - Compare: Diffusion vs Flow vs GAN
   - Compare: WavLM vs HuBERT vs Whisper
   - Output: docs/architecture.md
   - Why: Need to make design decisions

4. **Architecture proposal**: Draft 1-page proposal
   - Based on research findings
   - Include: Design choices, rationale, budget estimate
   - Output: Add to RESEARCH_PLAN.md
   - Why: Need human approval before implementation

### Priority: MEDIUM
5. **Git commit**: Commit today's work
   - Message: "Initial project structure and documentation"
   - Include: All new files

6. **Verify Modal**: Test Modal access if human confirms
   - Try: `modal --version`
   - Try: Simple test job
   - Why: Unblock Phase 1 experiments

### Waiting On Human
- GCS bucket setup (blocking data pipeline)
- Modal credentials confirmation (blocking GPU experiments)
- Strategic decisions (Phase 0 timeline, paper venue, quality vs speed)

---

## Decisions Made Today

### Documentation Approach
- **Decision**: Use markdown + git, not W&B initially
- **Rationale**: Simpler, no external dependencies, async-friendly
- **Can revisit**: Add W&B later if needed for experiment tracking at scale

### Project Structure
- **Decision**: Separate folders for experiments, data, source, docs
- **Rationale**: Standard ML research organization, clear separation of concerns
- **Based on**: Research on ML lab practices

### Communication Protocol
- **Decision**: HANDOFF.md for async status, research logs for details
- **Rationale**: Human needs action-oriented summary, logs provide full context
- **Format**: STAR framework (Status, Tasks, Actions, Review)

### Phase 0 Focus
- **Decision**: Start with strategic research before implementation
- **Rationale**: $5000 budget is limited, avoid wasting compute
- **Timeline**: ~1 week for Phase 0, adjust if needed

---

## Reflections

### What Went Well
- ✅ Clear understanding of project goals and constraints
- ✅ Comprehensive documentation framework established
- ✅ Good foundation for async collaboration
- ✅ Previous research provides strong starting point

### What Could Be Better
- ⚠️ Need to verify Modal access (can't proceed with GPU experiments without it)
- ⚠️ Need GCS bucket (blocking data pipeline)
- ⚠️ Haven't started actual research yet (Deep Research queries pending)

### Lessons Learned
- **Async collaboration requires structure**: Can't rely on shared context
- **Documentation is investment**: Takes time upfront but pays off
- **Research first, code second**: Better decisions = less wasted compute

---

## Links

- **CLAUDE.md**: `/Users/yn/Documents/code/unbound-v1/CLAUDE.md`
- **RESEARCH_PLAN.md**: `/Users/yn/Documents/code/unbound-v1/RESEARCH_PLAN.md`
- **HANDOFF.md**: `/Users/yn/Documents/code/unbound-v1/HANDOFF.md`
- **Previous research**: `DeepResearcher/research_sessions/`

---

## Time Breakdown

- Research on collaboration practices: 30 min
- Designing structure and workflow: 30 min
- Writing CLAUDE.md: 40 min
- Writing RESEARCH_PLAN.md: 30 min
- Writing HANDOFF.md: 20 min
- Writing supporting docs: 30 min
- This log: 20 min

**Total**: ~3 hours (went over estimate, but worthwhile investment)

---

**Status**: Project infrastructure complete, ready to start Phase 0 research
**Next**: Deep Research queries, architecture analysis, human input on blockers
